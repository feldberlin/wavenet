{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import librosa\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "from wavenet import model, train, sample, audio, datasets, utils, viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on simple Sines\n",
    "\n",
    "A very simple dataset, should be able to crush this. Sines all at 440 hz and 1.0 amplitude, but different phases.\n",
    "\n",
    "We will try to train in around 30 minutes. At batches of 16 running at 2.35 it/s, we have 30*60=1800 seconds so 765 steps to complete over batches of 16 1s audios. This is around 200 minutes of audio to iterate over, so 20 epochs of 10 minutes each seems reasonable. That's around 40 steps per epoch, so 40*16=640 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dry = False\n",
    "if dry:\n",
    "    os.environ['WANDB_MODE'] = 'dryrun'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.HParams(n_audio_chans=2)\n",
    "X, X_test = datasets.Sines(640, 1, p, hz=440, amp=1.0), datasets.Sines(640, 1, p, hz=440, amp=1.0)\n",
    "batch = datasets.to_tensor(X, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model.Wavenet(p)\n",
    "t = train.Trainer(m, X, X_test, train.HParams(max_epochs=20, batch_size=16, num_workers=10, learning_rate=0.0021), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_i = viz.plot_track(batch, n_samples=p.receptive_field_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(audio.mu_expand(batch[track_i].numpy(), p), rate=p.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, track = sample.sample(m, decoder=utils.decode_nucleus(), n_samples=32000, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.plot_track(track, n_samples=p.receptive_field_size() // 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(track[0], rate=p.sampling_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
