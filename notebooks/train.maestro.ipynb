{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import librosa\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "from wavenet import model, train, sample, audio, datasets, utils, viz, debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on Maestro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.HParams(\n",
    "    embed_inputs=True, \n",
    "    n_audio_chans=1, \n",
    "    squash_to_mono=True,\n",
    "    n_chans=256\n",
    ")\n",
    "\n",
    "pp.pprint(dict(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = train.HParams(\n",
    "    max_epochs=2, \n",
    "    batch_size=12, \n",
    "    num_workers=8, \n",
    "    learning_rate=0.0044\n",
    ")\n",
    "\n",
    "pp.pprint(dict(tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.seed(p)\n",
    "nas_path = Path('/srv/datasets/maestro/maestro-v2.0.0')\n",
    "ssd_path = Path('/srv/datasets-ssd/maestro/maestro-v2.0.0')\n",
    "ds_train, ds_test = datasets.maestro(nas_path, 2017, p, ssd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.seed(p)\n",
    "m = model.Wavenet(p)\n",
    "debug.summarize(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = train.Trainer(m, ds_train, ds_test, tp, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_i = viz.plot_random_track(ds_train)\n",
    "track, *_ = ds_train[track_i]\n",
    "ipd.Audio(audio.mu_expand(track.squeeze().numpy(), p), rate=p.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.seed(p)\n",
    "t.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.seed(p)\n",
    "tracks, logits, g = sample.fast(m, ds_train.transforms, utils.decode_nucleus(), n_samples=32000, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for track in tracks:\n",
    "    track = ds_train.transforms.normalise(track.numpy())\n",
    "    track = audio.mu_expand(track, p)\n",
    "    ipd.display(ipd.Audio(track, rate=p.sampling_rate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-wavenet",
   "language": "python",
   "name": ".venv-wavenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
