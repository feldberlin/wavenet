{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pprint\n",
    "import typing\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import librosa\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "from wavenet import model, train, sample, audio, datasets, utils, viz, debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on Dataset in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# this cell contains papermill tagged parameters\n",
    "# they can be overriden by the cli when training:  \n",
    "# papermill in.ipynb out.ipynb -p batch_norm True\n",
    "\n",
    "batch_norm = False\n",
    "learning_rate = 0.0044\n",
    "finder = False\n",
    "batch_size = 12\n",
    "max_epochs = 2\n",
    "with_all_chans = None\n",
    "root_dir: typing.Optional[Path] = None\n",
    "cache_dir: typing.Optional[Path] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if root_dir:\n",
    "    root_dir = Path(root_dir)\n",
    "else:\n",
    "    raise Exception('provide a root_dir to read from.')\n",
    "    \n",
    "if cache_dir:\n",
    "    cache_dir = Path(cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.HParams(\n",
    "    embed_inputs=True, \n",
    "    n_audio_chans=1, \n",
    "    squash_to_mono=True,\n",
    "    batch_norm=batch_norm\n",
    ")\n",
    "\n",
    "if with_all_chans:\n",
    "    p = p.with_all_chans(with_all_chans)\n",
    "    \n",
    "pp.pprint(dict(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = train.HParams(\n",
    "    max_epochs=max_epochs, \n",
    "    batch_size=batch_size, \n",
    "    num_workers=8, \n",
    "    finder=finder, \n",
    "    learning_rate=learning_rate\n",
    ")\n",
    "\n",
    "pp.pprint(dict(tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.seed(p)\n",
    "ds_train = datasets.Tracks.from_dir(p, root_dir, cache_dir)\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = len(ds_train)\n",
    "n_steps = tp.n_steps(n_examples)\n",
    "n_examples, n_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "utils.seed(p)\n",
    "m = model.Wavenet(p)\n",
    "debug.summarize(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = train.Trainer(m, ds_train, None, tp, None)\n",
    "t.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_i = viz.plot_random_track(ds_train)\n",
    "track, *_ = ds_train[track_i]\n",
    "ipd.Audio(audio.mu_expand(track.squeeze().numpy(), p), rate=p.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "utils.seed(p)\n",
    "t.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.seed(p)\n",
    "tracks, logits, g = sample.fast(m, ds_train.transforms, utils.decode_nucleus(), n_samples=32000, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for track in tracks:\n",
    "    track = ds_train.transforms.normalise(track.numpy())\n",
    "    track = audio.mu_expand(track, p)\n",
    "    ipd.display(ipd.Audio(track, rate=p.sampling_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.metrics.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-wavenet",
   "language": "python",
   "name": ".venv-wavenet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
